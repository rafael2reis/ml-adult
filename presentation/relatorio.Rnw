\documentclass{article}
\usepackage[portuguese]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[backend=bibtex, sorting=none]{biblatex}
\usepackage{mathtools}
\bibliography{references}

<<setup, include=FALSE, cache=FALSE, echo=FALSE>>=
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
@

\sloppy

\title{Um Classificador de Renda\\ para o Adult Data Set}
\author{Luis Felipe Müller \\ \texttt{lhenriques@inf.puc-rio.br}
  \and Rafael Reis \\ \texttt{rrsilva@inf.puc-rio.br}}

\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle

\begin{abstract}
Este trabalho tem como objetivo construir um classificador binário de renda para o Adult Data Set, cuja acurácia seja melhor do que a maior já registrada na literatura (85.9\%). Foram gerados alguns modelos de aprendizado de máquina a partir de diferentes algoritmos. Também foi utilizado o método de indução de atributos binários. Um comitê com os resultados dos três melhores algoritmos produziu uma acurácia de 86.42\%.
\end{abstract}

\section{Introdução}

Classificadores binários são modelos clássicos de aprendizado de máquina. Um exemplo é a tarefa de classficar uma mensagem como \emph{spam} ou não-\emph{spam}. Esses problemas pertecem à categoria de aprendizado \emph{supervisionado}, que consiste em predizer, ou estimar, uma \emph{saída} baseada e uma ou mais \emph{entradas} \cite{James:2014:ISL:2517747}.

\section{Base de Dados}

O Adult Data Set \cite{adultwebsite} é uma base de dados do UCI Machine Learning Repository \cite{Lichman:2013}, gerada a partir de dados do censo americano de 1994. O \emph{data set} possui 14 atributos, sendo 8 categóricos e 6 numéricos, como idade, educação, estado civil, dentre outros. São disponibilizados 2 arquivos, um para o conjunto de treino (com 32.561 registros) e o outro de teste (com 16.281).

Este trabalho, porém, utiliza o Adult Data Set um pouco modificado: seguindo as recomendações da página \emph{web} da base, foram removidos todos os registros que continham algum valor NA, tanto do conjunto de treino, quanto do conjunto de teste. Assim, o \emph{dataset} fica com um total de 45.222 registros, dos quais 30.162 são para treino e 15.060 para teste.

O Adult Data Set foi citado pela primeira vez em \cite{kohavi-nbtree} e, desde então, é utilizado, principalmente, para medir a qualidade de novos métodos de aprendizado de máquina \cite{pavlov2000scaling} \cite{cano2003using} \cite{hardt2012simple}.

\section{Tarefa}

A tarefa associada a esta base é uma classficação binária: predizer se uma pessoa possui renda maior do que \$50K ao ano. O atributo \emph{over50K} contém essa informação: ele possui valor ``>50K'',  se a pessoa apresenta renda maior do que \$50K, ou ``<=50K'',  caso contrário.

Em todo o conjunto, 75.22\% dos registros estão classificados como ``<=50K'', que será utilizado como \emph{baseline} estatístico. Junto com as melhores acurácias encontradas na literatura para esta tarefa \cite{kohavi1996scaling}, temos a seguinte tabela:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|}
\hline
Algo & Acurácia (\%) \\
\hline
NBTree & 85.90 \\
\hline
Decision Tree & 84.46 \\
\hline
Naive Bayes & 83.88 \\
\hline
\emph{Baseline} estatístico & 76.07 \\
\hline
\end{tabular}
\caption{Acurácia para a tarefa do Adult Data Set}
\label{table:acuracia}
\end{table}

O objetivo deste trabalho é atingir uma acurácia melhor do que as apresentadas.

\section{Preparação dos Dados}

Os arquivos com as bases de treino e de teste precisaram ser tratados antes da construção do modelo no framework Weka. Inicialmente, os registros que possuíam algum valor NA foram removidos, tanto da base de treino, quanto da de teste.

Foi verificado que, em certos atributos categóricos, apareciam valores na base de teste que não existiam na base de treino. Isso impedia o carregamento do conjunto de teste para a validação no Weka. A solução encontrada foi a criação de um \emph{script} na linguagem R que convertia as bases em formato txt/csv para o formato \emph{arff}, utilizado pelo Weka.

Também foi necessário limpar a base de treino, que possuía um caracter ``.'' ao final de cada linha, o que alterava o valor do atributo com o valor da classificação.

\section{Classificadores}

Nesta seção, apresentamos três classificadores: NBTree, Decision Tree e Rotation Forest. O primeiro foi construídos a fim de atingir os resultados já apresentados na literatura. Os dois últimos tiveram como objetivo melhorar a maior acurácia registrada até então para o Adult Data Set. A seguir, uma descrição de cada algoritmo.

\subsection{NBTree}

NBTree foi proposto em \cite{kohavi1996scaling} e é um híbrido entre as árvores de decisão e o Naive Bayes: os nós da árvore de decisão contêm partições univariadas, como os das árvores de decisão ordinárias, mas as folhas contêm classificadores Naive Bayes.

Especialmente, em bases de dados maiores, os resultados do NBTree são melhores do que os das árvores de decisão e do Naive Bayes \cite{kohavi1996scaling}.

\subsection{Decision Tree}

A Árvore de Decisão é um dos métodos mais práticos e amplamente utilizados para inferência indutiva \cite{michalski2013machine}. Basicamente, o algoritmo faz uma construção \emph{top-down} da árvore, utilizando a pergunta ``qual atributo deve ser testado neste nó?''. Para responder a essa pergunta, cada atributo é avaliado utilizando um teste estatístico para determinar quão bem ele sozinho classifica os exemplos de teste. Em geral, a medida utilizada no teste é a \emph{entropia}. 

\subsection{Rotation Forest}

Rotation Forest foi apresentado em \cite{rodriguez2006rotation}.

\section{Indução de Atributos}

Baseado em \cite{fernandes2012entropy}, foram gerados atributos binários para tentar melhorar a acurácia da classificação. A partir da árvore de decisão construída pelo J48 do Weka, de início, foram gerados 100 atributos binários, apenas para efeitos de teste. Depois, foram gerados 723 atributos, que correspondiam a toda a árvore. Mais tarde, tentou-se refazer a árvore, modificando-se alguns parâmetros do algoritmo, e um total de 946 atributos foram gerados.

Após aplicar os algoritmos levando-se em conta as \emph{features} geradas, verificou-se que os modelos que incluíam apenas os 100 obtiveram os melhores resultados, mas não melhor do que o \emph{dataset} sem os atributos induzidos. Ao final, como será explicado a seguir, o resultado do modelo com 100 atributos gerados foi aproveitado na etapa de comitê.

\section{Resultados}

Para gerar os resultados, foi utilizado o framework para aprendizado de máquina Weka. Os modelos foram construídos e validados utilizando, respectivamente, o conjunto de treino e o de teste. Foram encontrados os seguintes valores para as acurácias:

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|}
\hline
 Algo & Acurácia(\%) \\
\hline
Rotation Forest & 86.2882 \\
\hline
Decision Tree & 86.1687 \\
\hline
Rotation Forest(IA) & 86.1288 \\
\hline
NBTree & 85.7105 \\
 \hline
\end{tabular}
\caption{Acurácias}
\label{table:resultados}
\end{table}

A seguir, os resultados detalhados para cada algoritmo:

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
TP Rate & FP Rate & Precision & Recall & F-Measure & ROC Area & Class \\
\hline
0.935 & 0.489 & 0.859 & 0.935 & 0.895 & 0.889 & <=50K \\
\hline
0.511 & 0.065 & 0.712 & 0.511 & 0.595 & 0.889 & >50K \\
\hline
\end{tabular}
\caption{Resultados por Classe: NBTree}
\label{table:1}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
a & b & $\leftarrow$ classified as \\
\hline
11579 & 805 & a = <=50K \\
\hline
1905 & 1992 & b = >50K \\
\hline
\end{tabular}
\caption{Matrix de Confusão NBTree}
\label{table:2}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
TP Rate & FP Rate & Precision & Recall & F-Measure & ROC Area & Class \\
\hline
0.933 & 0.342 & 0.897 & 0.933 & 0.914 & 0.919 & <=50K \\
\hline
0.658 & 0.067 & 0.756 & 0.658 & 0.703 & 0.919 & >50K \\
\hline
\end{tabular}
\caption{Resultados por Classe: Rotation Forest (IA)}
\label{table:3}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
 a & b & $\leftarrow$ classified as \\
 \hline
11555 & 829 & a = <=50K \\
\hline
1334 & 2563 & b = >50K \\
 \hline
\end{tabular}
\caption{Matrix de Confusão Rotation Forest (IA)}
\label{table:4}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
TP Rate & FP Rate & Precision & Recall & F-Measure & ROC Area & Class \\
\hline
0.999 & 0.007 & 0.998 & 0.999 & 0.999 & 1 & <=50K \\
\hline
0.993 & 0.001 & 0.998 & 0.993 & 0.995 & 1 & >50K \\
\hline
\end{tabular}
\caption{Resultados por Classe: Decision Tree}
\label{table:5}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
 a & b & $\leftarrow$ classified as \\
 \hline
 12376 & 8 & a = <=50K \\
 \hline
 28 & 3869 & b = >50K \\
 \hline
\end{tabular}
\caption{Matrix de Confusão Decision Tree}
\label{table:6}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
TP Rate & FP Rate & Precision & Recall & F-Measure & ROC Area & Class \\
\hline
1 & 0.007 & 0.998 & 1 & 0.999 & 1 & <=50K \\
\hline
0.993 & 0 & 0.999 & 0.993 & 0.996 & 1 & >50K \\
\hline
\end{tabular}
\caption{Resultados por Classe: Rotation Forest}
\label{table:7}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
 a & b & $\leftarrow$ classified as \\
 \hline
12382 & 2 & a = <=50K \\
\hline
28 & 3869 & b = >50K \\
 \hline
\end{tabular}
\caption{Matrix de Confusão Rotation Forest}
\label{table:8}
\end{table}

\section{Conclusão}

Para a tarefa de classificação de renda do Adult Data Set, .

\printbibliography

\end{document}